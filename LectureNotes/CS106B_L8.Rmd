---
title: "CS106B: Programming Abstractions"
subtitle: "Lecture 8: Big-O and Algorithmic Analysis"
author: "Olivia Beyer Bruvik"
date: "Fall 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

# Lecture 8 {.tabset}

## Topics
- Asymptomatic analysis
- "Big O" notation
- Quantitatively and qualitatively analysis of algorithms. 

## Binary Search
### Recursive algorithm
- Elegant solution to the problem of too much data
- $O(log_2(N))$: worst case cost is number of times we can divide length in half

### Implementation
```{Rcpp, eval = FALSE}
bool binarySearch(Vector<int>& data, int key) {
  if (data.size() == 0) {
    return false;
  } if (key == data[midpoint]) {
    return true;
  } else if (key < data[midpoint]) {
    return binarySearch(data[first half only], key)
  } else {
    return binarySearch(data[second half only], key)
  }
}
```

## Big-O notation
### Formal definition

$$
f(n) \space is \space O(g(n)) \text{ if and only if} \\
\text{ there exist positive constants } x \space and \space n_0 \text{ such that } \\
f(n) \leq c * g(n) \text{ for all } n \geq n_0 \\
$$

### Applications:
- compare the number of steps to run these functions;
- predict how much time it will take to compute for arbitrary input N;
- categorize amount of work to be done in general terms (rate of growth & limits).
    
### Performance
- Worst case scenario: O(log n)
- Best-case scenario: O(1)
- Average Performance: O(log n)
- Worst-case space complexity: O(1)
- Efficiency is not always a virtue: accuracy vs.  efficiency trade off

#### Implications: $O(N^2 - 2N + 1)$ --> $O(N^2)$
- Only consider the largest term of the polynomial:
- N - 1 is negligible (rate important)
- constant c is negligible

### Naive implementation of the Fibonacci Sequence 
Big O: $O(1.6^n)$

```{Rcpp, eval = FALSE}
int fib(int n) {
  if (n == 0) {
    return 0;
  } else if (n == 1) {
    return 1;
  } else {
    return fib(n - 1) + fib(n - 2);
  }
}
```